{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Final Project\n",
    "**Due Date:** January 29, 2026, 23:59  \n",
    "\n",
    "**Group:** Cuircuit Synergy  \n",
    "\n",
    "**Created By:** Jeremia Baumgartner, Lorenz Buchinger, Tim Zw√∂lfer  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Initial Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': [12, 8],\n",
    "    'figure.dpi': 150,\n",
    "    'figure.autolayout': True,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'font.size': 12\n",
    "})\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_data = pd.read_csv('traffic_accidents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## A. Data Preprocessing and Data Quality (70 points)\n",
    "---\n",
    "**Assigned to Lorenz**\n",
    "- Dataset overview (dimensions, columns, types, time range, sampling rate, missingness\n",
    "summary) (10 points)\n",
    "- Basic statistical analysis using pandas (descriptives, grouped stats, quantiles) (10 points)\n",
    "- Original data quality analysis with visualization (missingness patterns, outliers, dupli-\n",
    "cates, timestamp gaps, inconsistent units) (20 points)\n",
    "- Data preprocessing pipeline (cleaning steps, handling missing data, outliers strategy, re-\n",
    "sampling or alignment if needed, feature engineering basics) (20 points)\n",
    "- Preprocessed vs original comparison (before/after visuals plus commentary on what changed\n",
    "and why) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## B. Visualization and Exploratory Analysis (55 points)\n",
    "---\n",
    "**Assigned to Jeremia**\n",
    "- Time-series visualizations (raw, smoothed, rolling mean or windowed views) (10 points)\n",
    "- Distribution analysis with histograms and density style plots where applicable (10 points)\n",
    "- Correlation analysis and heatmaps (Pearson and at least one alternative such as Spearman,\n",
    "with short interpretation) (10 points)\n",
    "- Daily or periodic pattern analysis (day-of-week, hour-of-day, seasonality indicators, or\n",
    "test-cycle patterns) (15 points)\n",
    "- Summary of observed patterns as short check statements (similar to True/False style)\n",
    "with evidence (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## C. Probability and Event Analysis (45 points)\n",
    "---\n",
    "**Assigned to Tim**\n",
    "- Threshold-based probability estimation for events (define event, justify threshold, compute\n",
    "empirical probability) (15 points)\n",
    "- Cross tabulation analysis for two variables (10 points)\n",
    "- Conditional probability analysis (at least two meaningful conditional relationships) (15\n",
    "points)\n",
    "- Summary of observations and limitations (what could bias these estimates, what assump-\n",
    "tions were made) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## D. Statistical Theory Applications (45 points)\n",
    "---\n",
    "**Assigned to Tim**\n",
    "- Law of Large Numbers demonstration (15 points)\n",
    "- Central Limit Theorem application (sampling distributions, effect of sample size, interpretation) (25 points)\n",
    "- Result interpretation and sanity checks (what would invalidate your conclusion, what you verified) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## E. Regression and Predictive Modeling (45 points)\n",
    "---\n",
    "**Assigned to Lorenz**\n",
    "- Define a prediction target and features (justify why they make sense) (10 points)\n",
    "- Linear or polynomial model selection (include rationale and show at least two candidates)\n",
    "(10 points)\n",
    "- Model fitting and validation (train-test split appropriate for time-series. e.g., time-based split) (15 points)\n",
    "- Residual analysis and interpretation (errors, bias, failure cases, what to improve next) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## F. Dimensionality Reduction and Statistical Tests (40 points)\n",
    "---\n",
    "**Assigned to Jeremia**\n",
    "### Part 1. Dimensionality Reduction (25 points)\n",
    "- PCA projection and interpretation (variance explained, what clusters or separations mean) (10 points)\n",
    "- t-SNE embedding with justified hyperparameters (perplexity or similar) and interpretation (7 points)\n",
    "- UMAP embedding with justified hyperparameters (neighbors, min dist or similar) and interpretation (8 points)\n",
    "### Part 2. Hypothesis Tests (15 points)\n",
    "Perform at least three tests. Each test must include: null hypothesis, why the test is appropriate, assumptions, p-value, and practical interpretation.\n",
    "- Chi-square test (choose one):\n",
    "    - Chi-square test of independence (use a contingency table from two categorical or binned variables), or\n",
    "    - Chi-square goodness-of-fit (compare observed counts to an expected distribution you justify). (5 points)\n",
    "- One mean or location comparison test (choose one): t-test, Welch t-test, Mann-Whitney U, or ANOVA (5 points)\n",
    "- One time-series relevant test (choose one): stationarity test (ADF or KPSS), Ljung-Box for autocorrelation, or change-point style test if justified (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
